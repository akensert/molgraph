{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from molgraph.chemistry import MolecularGraphEncoder\n",
    "from molgraph.chemistry import AtomFeaturizer  \n",
    "from molgraph.chemistry import BondFeaturizer\n",
    "from molgraph.chemistry import features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a `MolecularGraphEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolecularGraphEncoder(atom_encoder=AtomFeaturizer(features=[Symbol(allowable_set={'N', 'C', 'O'}, ordinal=False, oov_size=1), Hybridization(allowable_set={'SP3', 'SP', 'SP2'}, ordinal=False, oov_size=1), HydrogenDonor(), HydrogenAcceptor(), Hetero()], dtype='float32', ndim=11), bond_encoder=BondFeaturizer(features=[BondType(allowable_set={'DOUBLE', 'AROMATIC', 'TRIPLE', 'SINGLE'}, ordinal=False, oov_size=0), Rotatable()], dtype='float32', ndim=5), positional_encoding_dim=20, self_loops=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_encoder = AtomFeaturizer([\n",
    "    features.Symbol({'C', 'N', 'O'}, oov_size=1),\n",
    "    features.Hybridization({'SP', 'SP2', 'SP3'}, oov_size=1),\n",
    "    features.HydrogenDonor(),\n",
    "    features.HydrogenAcceptor(),\n",
    "    features.Hetero()\n",
    "])\n",
    "\n",
    "bond_encoder = BondFeaturizer([\n",
    "    features.BondType({'SINGLE', 'DOUBLE', 'TRIPLE', 'AROMATIC'}),\n",
    "    features.Rotatable()\n",
    "])\n",
    "\n",
    "mol_encoder = MolecularGraphEncoder(atom_encoder, bond_encoder)\n",
    "mol_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain dataset as `pd.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound ID</th>\n",
       "      <th>ESOL predicted log solubility in mols per litre</th>\n",
       "      <th>Minimum Degree</th>\n",
       "      <th>Molecular Weight</th>\n",
       "      <th>Number of H-Bond Donors</th>\n",
       "      <th>Number of Rings</th>\n",
       "      <th>Number of Rotatable Bonds</th>\n",
       "      <th>Polar Surface Area</th>\n",
       "      <th>measured log solubility in mols per litre</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amigdalin</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>1</td>\n",
       "      <td>457.432</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>202.32</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fenfuram</td>\n",
       "      <td>-2.885</td>\n",
       "      <td>1</td>\n",
       "      <td>201.225</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>42.24</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>Cc1occc1C(=O)Nc2ccccc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>citral</td>\n",
       "      <td>-2.579</td>\n",
       "      <td>1</td>\n",
       "      <td>152.237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17.07</td>\n",
       "      <td>-2.06</td>\n",
       "      <td>CC(C)=CCCC(C)=CC(=O)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Compound ID  ESOL predicted log solubility in mols per litre  \\\n",
       "0   Amigdalin                                           -0.974   \n",
       "1    Fenfuram                                           -2.885   \n",
       "2      citral                                           -2.579   \n",
       "\n",
       "   Minimum Degree  Molecular Weight  Number of H-Bond Donors  Number of Rings  \\\n",
       "0               1           457.432                        7                3   \n",
       "1               1           201.225                        1                2   \n",
       "2               1           152.237                        0                0   \n",
       "\n",
       "   Number of Rotatable Bonds  Polar Surface Area  \\\n",
       "0                          7              202.32   \n",
       "1                          2               42.24   \n",
       "2                          4               17.07   \n",
       "\n",
       "   measured log solubility in mols per litre  \\\n",
       "0                                      -0.77   \n",
       "1                                      -3.30   \n",
       "2                                      -2.06   \n",
       "\n",
       "                                              smiles  \n",
       "0  OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...  \n",
       "1                             Cc1occc1C(=O)Nc2ccccc2  \n",
       "2                               CC(C)=CCCC(C)=CC(=O)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = tf.keras.utils.get_file(\n",
    "    fname='ESOL.csv',\n",
    "    origin='http://deepchem.io.s3-website-us-west-1.amazonaws.com/datasets/ESOL.csv',\n",
    ")\n",
    "df = pd.read_csv(path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain SMILES (\"x\"; string representation of molecules) and associated labels (\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df['smiles'].values, df['measured log solubility in mols per litre'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain `GraphTensor` (\"x\") from SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphTensor(node_feature=<tf.RaggedTensor: shape=(1128, None, 11), dtype=float32, ragged_rank=1, row_splits_dtype=int32>, edge_feature=<tf.RaggedTensor: shape=(1128, None, 5), dtype=float32, ragged_rank=1, row_splits_dtype=int32>, positional_encoding=<tf.RaggedTensor: shape=(1128, None, 20), dtype=float32, ragged_rank=1, row_splits_dtype=int32>, edge_dst=<tf.RaggedTensor: shape=(1128, None), dtype=int32, ragged_rank=1, row_splits_dtype=int32>, edge_src=<tf.RaggedTensor: shape=(1128, None), dtype=int32, ragged_rank=1, row_splits_dtype=int32>)\n",
      "\n",
      "node_feature shape: (1128, None, 11)\n",
      "edge_dst shape:     (1128, None)\n",
      "edge_src shape:     (1128, None)\n",
      "edge_feature shape: (1128, None, 5)\n"
     ]
    }
   ],
   "source": [
    "x = mol_encoder(x)\n",
    "\n",
    "print(x, end='\\n\\n')\n",
    "print('node_feature shape:', x.node_feature.shape)\n",
    "print('edge_dst shape:    ', x.edge_dst.shape)\n",
    "print('edge_src shape:    ', x.edge_src.shape)\n",
    "print('edge_feature shape:', x.edge_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph neural network (GNN) `layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': typing.Union[int, NoneType],\n",
       " 'use_edge_features': bool,\n",
       " 'num_heads': int,\n",
       " 'merge_mode': typing.Union[str, NoneType],\n",
       " 'self_projection': bool,\n",
       " 'batch_norm': bool,\n",
       " 'residual': bool,\n",
       " 'dropout': typing.Union[float, NoneType],\n",
       " 'attention_activation': typing.Union[NoneType, str, typing.Callable[[tensorflow.python.framework.ops.Tensor], tensorflow.python.framework.ops.Tensor]],\n",
       " 'activation': typing.Union[NoneType, str, typing.Callable[[tensorflow.python.framework.ops.Tensor], tensorflow.python.framework.ops.Tensor]],\n",
       " 'use_bias': bool,\n",
       " 'kernel_initializer': typing.Union[str, keras.initializers.initializers_v2.Initializer],\n",
       " 'bias_initializer': typing.Union[str, keras.initializers.initializers_v2.Initializer],\n",
       " 'kernel_regularizer': typing.Union[keras.regularizers.Regularizer, NoneType],\n",
       " 'bias_regularizer': typing.Union[keras.regularizers.Regularizer, NoneType],\n",
       " 'activity_regularizer': typing.Union[keras.regularizers.Regularizer, NoneType],\n",
       " 'kernel_constraint': typing.Union[keras.constraints.Constraint, NoneType],\n",
       " 'bias_constraint': typing.Union[keras.constraints.Constraint, NoneType]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from molgraph.layers import (\n",
    "    GCNConv, \n",
    "    GCNIIConv, \n",
    "    GINConv, \n",
    "    GraphSageConv, \n",
    "    GATConv, \n",
    "    GatedGCNConv, \n",
    "    GraphTransformerConv, \n",
    "    GMMConv, \n",
    "    MPNNConv, \n",
    "    Readout\n",
    ")\n",
    "\n",
    "from molgraph.layers import ops as layer_ops\n",
    "\n",
    "GATConv.__init__.__annotations__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass `GraphTensor` directly to `layer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphTensor(node_feature=<tf.RaggedTensor: shape=(1128, None, 128), dtype=float32, ragged_rank=1, row_splits_dtype=int32>, edge_feature=<tf.RaggedTensor: shape=(1128, None, 128), dtype=float32, ragged_rank=1, row_splits_dtype=int32>, positional_encoding=<tf.RaggedTensor: shape=(1128, None, 20), dtype=float32, ragged_rank=1, row_splits_dtype=int32>, edge_dst=<tf.RaggedTensor: shape=(1128, None), dtype=int32, ragged_rank=1, row_splits_dtype=int32>, edge_src=<tf.RaggedTensor: shape=(1128, None), dtype=int32, ragged_rank=1, row_splits_dtype=int32>)\n",
      "\n",
      "GraphTensor(node_feature=<tf.Tensor: shape=(14991, 128), dtype=float32>, edge_feature=<tf.Tensor: shape=(30856, 128), dtype=float32>, positional_encoding=<tf.Tensor: shape=(14991, 20), dtype=float32>, edge_dst=<tf.Tensor: shape=(30856,), dtype=int32>, edge_src=<tf.Tensor: shape=(30856,), dtype=int32>, graph_indicator=<tf.Tensor: shape=(14991,), dtype=int32>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = GATConv(units=128, use_edge_features=True, num_heads=8, merge_mode='concat')\n",
    "\n",
    "out1 = layer(x)                 # with nested ragged tensors\n",
    "out2 = layer(x.merge())         # with nested tensors\n",
    "\n",
    "print(out1)\n",
    "print()\n",
    "print(out2)\n",
    "\n",
    "tf.reduce_all(out1.node_feature.flat_values == out2.node_feature).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom `layer`\n",
    "\n",
    "`molgraph.layers.ops` (in this notebook `layer_ops`) supply various helper functions for implementing a GNN layer. Below e.g., `layer_ops.propagate_node_features` is used to aggregate information from source nodes to destination nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without `edge_feature`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensor(node_feature=<tf.RaggedTensor: shape=(1128, None, 128), dtype=float32, ragged_rank=1, row_splits_dtype=int32>, edge_feature=<tf.RaggedTensor: shape=(1128, None, 5), dtype=float32, ragged_rank=1, row_splits_dtype=int32>, positional_encoding=<tf.RaggedTensor: shape=(1128, None, 20), dtype=float32, ragged_rank=1, row_splits_dtype=int32>, edge_dst=<tf.RaggedTensor: shape=(1128, None), dtype=int32, ragged_rank=1, row_splits_dtype=int32>, edge_src=<tf.RaggedTensor: shape=(1128, None), dtype=int32, ragged_rank=1, row_splits_dtype=int32>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class MyGCNConv(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel', \n",
    "            shape=(input_shape[-1], self.units),\n",
    "            dtype=tf.float32,\n",
    "            trainable=True)\n",
    "        self.built = True\n",
    "    \n",
    "    def call(self, graph_tensor):\n",
    "        graph_tensor_orig = graph_tensor\n",
    "        if isinstance(graph_tensor.node_feature, tf.RaggedTensor):\n",
    "            graph_tensor = graph_tensor.merge()\n",
    "            \n",
    "        node_feature_transformed = tf.matmul(graph_tensor.node_feature, self.kernel)\n",
    "        node_feature_aggregated = layer_ops.propagate_node_features(\n",
    "            node_feature_transformed, \n",
    "            graph_tensor.edge_src, \n",
    "            graph_tensor.edge_dst, \n",
    "            mode='mean')\n",
    "        return graph_tensor_orig.update({'node_feature': node_feature_aggregated})\n",
    "    \n",
    "my_layer = MyGCNConv(128)\n",
    "\n",
    "my_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `edge_feature`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensor(node_feature=<tf.RaggedTensor: shape=(1128, None, 128), dtype=float32, ragged_rank=1, row_splits_dtype=int32>, edge_feature=<tf.RaggedTensor: shape=(1128, None, 128), dtype=float32, ragged_rank=1, row_splits_dtype=int32>, positional_encoding=<tf.RaggedTensor: shape=(1128, None, 20), dtype=float32, ragged_rank=1, row_splits_dtype=int32>, edge_dst=<tf.RaggedTensor: shape=(1128, None), dtype=int32, ragged_rank=1, row_splits_dtype=int32>, edge_src=<tf.RaggedTensor: shape=(1128, None), dtype=int32, ragged_rank=1, row_splits_dtype=int32>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyGCNConvWithGates(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.built_from_tensor = False\n",
    "    \n",
    "    def build_from_tensor(self, graph_tensor):\n",
    "        \"\"\"Custom build method (not using the builtin `build`)\"\"\"\n",
    "        \n",
    "        self.kernel_node = self.add_weight(\n",
    "            name='kernel_node', \n",
    "            shape=(graph_tensor.node_feature.shape[-1], self.units),\n",
    "            dtype=tf.float32,\n",
    "            trainable=True)\n",
    "        \n",
    "        self.kernel_edge = self.add_weight(\n",
    "            name='kernel_edge', \n",
    "            shape=(graph_tensor.edge_feature.shape[-1], self.units),\n",
    "            dtype=tf.float32,\n",
    "            trainable=True)\n",
    "        \n",
    "        self.built_from_tensor = True\n",
    "    \n",
    "    def call(self, graph_tensor):\n",
    "        \n",
    "        graph_tensor_orig = graph_tensor\n",
    "        if isinstance(graph_tensor.node_feature, tf.RaggedTensor):\n",
    "            graph_tensor = graph_tensor.merge()\n",
    "            \n",
    "        if not self.built_from_tensor:\n",
    "            self.build_from_tensor(graph_tensor)\n",
    "            \n",
    "        node_feature_transformed = tf.matmul(graph_tensor.node_feature, self.kernel_node)\n",
    "        edge_feature_transformed = tf.matmul(graph_tensor.edge_feature, self.kernel_edge)\n",
    "        \n",
    "        gate = tf.nn.leaky_relu(edge_feature_transformed)\n",
    "        gate = layer_ops.softmax_edge_weights(gate, graph_tensor.edge_dst)\n",
    "        \n",
    "        node_feature_aggregated = layer_ops.propagate_node_features(\n",
    "            node_feature_transformed, \n",
    "            graph_tensor.edge_src, \n",
    "            graph_tensor.edge_dst, \n",
    "            edge_weight=gate, \n",
    "            mode='mean')\n",
    "        \n",
    "        return graph_tensor_orig.update({\n",
    "            'node_feature': node_feature_aggregated,\n",
    "            'edge_feature': edge_feature_transformed\n",
    "        })\n",
    "    \n",
    "my_layer = MyGCNConvWithGates(128)\n",
    "\n",
    "my_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Keras models using GNN `layers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.permutation(np.arange(x.shape[0]))\n",
    "\n",
    "x_train = x[random_indices[:800]]\n",
    "x_test = x[random_indices[800:]]\n",
    "\n",
    "y_train = y[random_indices[:800]]\n",
    "y_test = y[random_indices[800:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Keras Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gcn_conv (GCNConv)          (None, None, 128)         4864      \n",
      "                                                                 \n",
      " gcn_conv_1 (GCNConv)        (None, None, 128)         33408     \n",
      "                                                                 \n",
      " gcn_conv_2 (GCNConv)        (None, None, 128)         33408     \n",
      "                                                                 \n",
      " segment_pooling_readout (Se  (None, 128)              0         \n",
      " gmentPoolingReadout)                                            \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,241\n",
      "Trainable params: 137,473\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import molgraph as mg\n",
    "\n",
    "sequential_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(type_spec=x_train.unspecific_spec),\n",
    "    GCNConv(128),\n",
    "    GCNConv(128),\n",
    "    GCNConv(128),\n",
    "    Readout(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "sequential_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 - 2s - loss: 0.9730 - mae: 0.7487 - 2s/epoch - 92ms/step\n",
      "Epoch 2/30\n",
      "25/25 - 0s - loss: 0.7365 - mae: 0.6299 - 130ms/epoch - 5ms/step\n",
      "Epoch 3/30\n",
      "25/25 - 0s - loss: 0.8885 - mae: 0.7109 - 128ms/epoch - 5ms/step\n",
      "Epoch 4/30\n",
      "25/25 - 0s - loss: 0.8271 - mae: 0.6752 - 125ms/epoch - 5ms/step\n",
      "Epoch 5/30\n",
      "25/25 - 0s - loss: 0.9101 - mae: 0.7191 - 123ms/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "25/25 - 0s - loss: 0.8767 - mae: 0.7117 - 123ms/epoch - 5ms/step\n",
      "Epoch 7/30\n",
      "25/25 - 0s - loss: 0.9032 - mae: 0.7313 - 127ms/epoch - 5ms/step\n",
      "Epoch 8/30\n",
      "25/25 - 0s - loss: 0.7146 - mae: 0.6390 - 130ms/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "25/25 - 0s - loss: 0.7188 - mae: 0.6373 - 125ms/epoch - 5ms/step\n",
      "Epoch 10/30\n",
      "25/25 - 0s - loss: 0.7070 - mae: 0.6392 - 125ms/epoch - 5ms/step\n",
      "Epoch 11/30\n",
      "25/25 - 0s - loss: 0.7260 - mae: 0.6365 - 124ms/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "25/25 - 0s - loss: 0.6799 - mae: 0.6171 - 123ms/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "25/25 - 0s - loss: 0.6146 - mae: 0.5803 - 125ms/epoch - 5ms/step\n",
      "Epoch 14/30\n",
      "25/25 - 0s - loss: 0.6220 - mae: 0.5930 - 124ms/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "25/25 - 0s - loss: 0.6246 - mae: 0.5726 - 126ms/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "25/25 - 0s - loss: 0.7218 - mae: 0.6366 - 122ms/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "25/25 - 0s - loss: 0.6364 - mae: 0.5875 - 127ms/epoch - 5ms/step\n",
      "Epoch 18/30\n",
      "25/25 - 0s - loss: 0.6468 - mae: 0.5960 - 125ms/epoch - 5ms/step\n",
      "Epoch 19/30\n",
      "25/25 - 0s - loss: 0.6423 - mae: 0.6003 - 130ms/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "25/25 - 0s - loss: 0.6277 - mae: 0.5855 - 129ms/epoch - 5ms/step\n",
      "Epoch 21/30\n",
      "25/25 - 0s - loss: 0.6929 - mae: 0.6245 - 124ms/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "25/25 - 0s - loss: 0.6010 - mae: 0.5749 - 126ms/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "25/25 - 0s - loss: 0.5565 - mae: 0.5598 - 122ms/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "25/25 - 0s - loss: 0.5079 - mae: 0.5203 - 122ms/epoch - 5ms/step\n",
      "Epoch 25/30\n",
      "25/25 - 0s - loss: 0.4929 - mae: 0.5117 - 123ms/epoch - 5ms/step\n",
      "Epoch 26/30\n",
      "25/25 - 0s - loss: 0.5878 - mae: 0.5747 - 122ms/epoch - 5ms/step\n",
      "Epoch 27/30\n",
      "25/25 - 0s - loss: 0.6131 - mae: 0.5945 - 123ms/epoch - 5ms/step\n",
      "Epoch 28/30\n",
      "25/25 - 0s - loss: 0.5328 - mae: 0.5229 - 122ms/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "25/25 - 0s - loss: 0.5169 - mae: 0.5304 - 129ms/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "25/25 - 0s - loss: 0.5519 - mae: 0.5611 - 123ms/epoch - 5ms/step\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.6617 - mae: 0.8993\n",
      "mse = 1.662\n",
      "mae = 0.899\n"
     ]
    }
   ],
   "source": [
    "sequential_model.compile('adam', 'mse', ['mae'])\n",
    "sequential_model.fit(x_train, y_train, epochs=30, verbose=2)\n",
    "mse, mae = sequential_model.evaluate(x_test, y_test)\n",
    "print(f\"{mse = :.3f}\\n{mae = :.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Keras functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 11)]              0         \n",
      "                                                                 \n",
      " gcn_conv_3 (GCNConv)        (None, 128)               4864      \n",
      "                                                                 \n",
      " gcn_conv_4 (GCNConv)        (None, 128)               33408     \n",
      "                                                                 \n",
      " gcn_conv_5 (GCNConv)        (None, 128)               33408     \n",
      "                                                                 \n",
      " segment_pooling_readout_1 (  (None, 128)              0         \n",
      " SegmentPoolingReadout)                                          \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,241\n",
      "Trainable params: 137,473\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(type_spec=x_train.merge().unspecific_spec)\n",
    "x = GCNConv(128)(inputs)\n",
    "x = GCNConv(128)(x)\n",
    "x = GCNConv(128)(x)\n",
    "x = Readout()(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "functional_model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "functional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 - 2s - loss: 4.2945 - mae: 1.6155 - 2s/epoch - 95ms/step\n",
      "Epoch 2/30\n",
      "25/25 - 0s - loss: 2.8229 - mae: 1.3541 - 124ms/epoch - 5ms/step\n",
      "Epoch 3/30\n",
      "25/25 - 0s - loss: 2.5423 - mae: 1.2628 - 124ms/epoch - 5ms/step\n",
      "Epoch 4/30\n",
      "25/25 - 0s - loss: 2.2094 - mae: 1.1681 - 131ms/epoch - 5ms/step\n",
      "Epoch 5/30\n",
      "25/25 - 0s - loss: 2.2424 - mae: 1.1842 - 126ms/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "25/25 - 0s - loss: 2.1514 - mae: 1.1649 - 123ms/epoch - 5ms/step\n",
      "Epoch 7/30\n",
      "25/25 - 0s - loss: 2.1544 - mae: 1.1625 - 125ms/epoch - 5ms/step\n",
      "Epoch 8/30\n",
      "25/25 - 0s - loss: 2.0617 - mae: 1.1226 - 125ms/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "25/25 - 0s - loss: 1.9535 - mae: 1.0972 - 124ms/epoch - 5ms/step\n",
      "Epoch 10/30\n",
      "25/25 - 0s - loss: 1.8884 - mae: 1.0562 - 128ms/epoch - 5ms/step\n",
      "Epoch 11/30\n",
      "25/25 - 0s - loss: 1.7336 - mae: 1.0230 - 123ms/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "25/25 - 0s - loss: 1.8817 - mae: 1.0589 - 122ms/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "25/25 - 0s - loss: 2.1456 - mae: 1.1702 - 122ms/epoch - 5ms/step\n",
      "Epoch 14/30\n",
      "25/25 - 0s - loss: 1.8322 - mae: 1.0374 - 122ms/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "25/25 - 0s - loss: 1.6195 - mae: 0.9901 - 130ms/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "25/25 - 0s - loss: 1.7879 - mae: 1.0409 - 124ms/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "25/25 - 0s - loss: 1.6963 - mae: 1.0117 - 122ms/epoch - 5ms/step\n",
      "Epoch 18/30\n",
      "25/25 - 0s - loss: 1.9636 - mae: 1.1082 - 123ms/epoch - 5ms/step\n",
      "Epoch 19/30\n",
      "25/25 - 0s - loss: 1.5552 - mae: 0.9764 - 121ms/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "25/25 - 0s - loss: 1.4910 - mae: 0.9229 - 121ms/epoch - 5ms/step\n",
      "Epoch 21/30\n",
      "25/25 - 0s - loss: 1.6384 - mae: 0.9632 - 122ms/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "25/25 - 0s - loss: 1.4377 - mae: 0.9229 - 124ms/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "25/25 - 0s - loss: 1.4288 - mae: 0.9025 - 127ms/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "25/25 - 0s - loss: 1.3637 - mae: 0.8990 - 123ms/epoch - 5ms/step\n",
      "Epoch 25/30\n",
      "25/25 - 0s - loss: 1.3672 - mae: 0.9024 - 122ms/epoch - 5ms/step\n",
      "Epoch 26/30\n",
      "25/25 - 0s - loss: 1.3272 - mae: 0.8645 - 124ms/epoch - 5ms/step\n",
      "Epoch 27/30\n",
      "25/25 - 0s - loss: 1.4394 - mae: 0.9266 - 124ms/epoch - 5ms/step\n",
      "Epoch 28/30\n",
      "25/25 - 0s - loss: 1.5398 - mae: 0.9567 - 131ms/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "25/25 - 0s - loss: 1.3044 - mae: 0.8750 - 130ms/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "25/25 - 0s - loss: 1.1937 - mae: 0.8326 - 129ms/epoch - 5ms/step\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.7347 - mae: 0.9907\n",
      "mse = 1.735\n",
      "mae = 0.991\n"
     ]
    }
   ],
   "source": [
    "functional_model.compile('adam', 'mse', ['mae'])\n",
    "functional_model.fit(x_train, y_train, epochs=30, verbose=2)\n",
    "mse, mae = functional_model.evaluate(x_test, y_test)\n",
    "print(f\"{mse = :.3f}\\n{mae = :.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Keras subclassing\n",
    "\n",
    "Creating a custom Keras model allow for more flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, gnn_units=128, dense_units=512):\n",
    "        super().__init__()\n",
    "        self.gcn_1 = GCNConv(gnn_units)\n",
    "        self.gcn_2 = GCNConv(gnn_units)\n",
    "        self.gcn_3 = GCNConv(gnn_units)\n",
    "        self.readout = Readout()\n",
    "        self.dense_1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dense_2 = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x0 = inputs\n",
    "        x1 = self.gcn_1(x0)\n",
    "        x2 = self.gcn_2(x1)\n",
    "        x3 = self.gcn_3(x2)\n",
    "        x1 = self.readout(x1)\n",
    "        x2 = self.readout(x2)\n",
    "        x3 = self.readout(x3)\n",
    "        x = tf.concat([x1, x2, x3], axis=1)\n",
    "        x = self.dense_1(x)\n",
    "        return self.dense_2(x)\n",
    "        \n",
    "        \n",
    "my_model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gcn_conv_9 (GCNConv)        multiple                  4864      \n",
      "                                                                 \n",
      " gcn_conv_10 (GCNConv)       multiple                  33408     \n",
      "                                                                 \n",
      " gcn_conv_11 (GCNConv)       multiple                  33408     \n",
      "                                                                 \n",
      " segment_pooling_readout_3 (  multiple                 0         \n",
      " SegmentPoolingReadout)                                          \n",
      "                                                                 \n",
      " dense_16 (Dense)            multiple                  197120    \n",
      "                                                                 \n",
      " dense_17 (Dense)            multiple                  513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,313\n",
      "Trainable params: 268,545\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, gnn_units=128, dense_units=512):\n",
    "        super().__init__()\n",
    "        self.gcn_1 = GCNConv(gnn_units)\n",
    "        self.gcn_2 = GCNConv(gnn_units)\n",
    "        self.gcn_3 = GCNConv(gnn_units)\n",
    "        self.readout = Readout()\n",
    "        self.dense_1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dense_2 = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x0 = inputs\n",
    "        x1 = self.gcn_1(x0)\n",
    "        x2 = self.gcn_2(x1)\n",
    "        x3 = self.gcn_3(x2)\n",
    "        x1 = self.readout(x1)\n",
    "        x2 = self.readout(x2)\n",
    "        x3 = self.readout(x3)\n",
    "        x = tf.concat([x1, x2, x3], axis=1)\n",
    "        x = self.dense_1(x)\n",
    "        return self.dense_2(x)\n",
    "        \n",
    "        \n",
    "my_model = MyModel()\n",
    "\n",
    "my_model(x_train) # build\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 - 3s - loss: 2.8839 - mae: 1.3493 - 3s/epoch - 110ms/step\n",
      "Epoch 2/30\n",
      "25/25 - 0s - loss: 2.6842 - mae: 1.2859 - 134ms/epoch - 5ms/step\n",
      "Epoch 3/30\n",
      "25/25 - 0s - loss: 2.2023 - mae: 1.1636 - 135ms/epoch - 5ms/step\n",
      "Epoch 4/30\n",
      "25/25 - 0s - loss: 2.1967 - mae: 1.1720 - 136ms/epoch - 5ms/step\n",
      "Epoch 5/30\n",
      "25/25 - 0s - loss: 2.1682 - mae: 1.1579 - 136ms/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "25/25 - 0s - loss: 1.9332 - mae: 1.0919 - 135ms/epoch - 5ms/step\n",
      "Epoch 7/30\n",
      "25/25 - 0s - loss: 1.9765 - mae: 1.1035 - 134ms/epoch - 5ms/step\n",
      "Epoch 8/30\n",
      "25/25 - 0s - loss: 2.1477 - mae: 1.1577 - 135ms/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "25/25 - 0s - loss: 1.9732 - mae: 1.1083 - 134ms/epoch - 5ms/step\n",
      "Epoch 10/30\n",
      "25/25 - 0s - loss: 1.7515 - mae: 1.0429 - 134ms/epoch - 5ms/step\n",
      "Epoch 11/30\n",
      "25/25 - 0s - loss: 1.6578 - mae: 1.0007 - 135ms/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "25/25 - 0s - loss: 1.7114 - mae: 1.0160 - 131ms/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "25/25 - 0s - loss: 1.5957 - mae: 0.9855 - 134ms/epoch - 5ms/step\n",
      "Epoch 14/30\n",
      "25/25 - 0s - loss: 1.7998 - mae: 1.0394 - 135ms/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "25/25 - 0s - loss: 1.7384 - mae: 1.0184 - 133ms/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "25/25 - 0s - loss: 1.6220 - mae: 1.0077 - 132ms/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "25/25 - 0s - loss: 1.5586 - mae: 0.9602 - 134ms/epoch - 5ms/step\n",
      "Epoch 18/30\n",
      "25/25 - 0s - loss: 1.4485 - mae: 0.9359 - 132ms/epoch - 5ms/step\n",
      "Epoch 19/30\n",
      "25/25 - 0s - loss: 1.5610 - mae: 0.9617 - 136ms/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "25/25 - 0s - loss: 1.4814 - mae: 0.9454 - 139ms/epoch - 6ms/step\n",
      "Epoch 21/30\n",
      "25/25 - 0s - loss: 1.3786 - mae: 0.8819 - 133ms/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "25/25 - 0s - loss: 1.4753 - mae: 0.9361 - 131ms/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "25/25 - 0s - loss: 1.3223 - mae: 0.8910 - 136ms/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "25/25 - 0s - loss: 1.7698 - mae: 1.0195 - 134ms/epoch - 5ms/step\n",
      "Epoch 25/30\n",
      "25/25 - 0s - loss: 1.4576 - mae: 0.9375 - 130ms/epoch - 5ms/step\n",
      "Epoch 26/30\n",
      "25/25 - 0s - loss: 1.3836 - mae: 0.9060 - 135ms/epoch - 5ms/step\n",
      "Epoch 27/30\n",
      "25/25 - 0s - loss: 1.2879 - mae: 0.8659 - 132ms/epoch - 5ms/step\n",
      "Epoch 28/30\n",
      "25/25 - 0s - loss: 1.1605 - mae: 0.8013 - 131ms/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "25/25 - 0s - loss: 1.2268 - mae: 0.8455 - 134ms/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "25/25 - 0s - loss: 1.2955 - mae: 0.8652 - 134ms/epoch - 5ms/step\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 2.0764 - mae: 1.0787\n",
      "mse = 2.076\n",
      "mae = 1.079\n"
     ]
    }
   ],
   "source": [
    "my_model.compile('adam', 'mse', ['mae'])\n",
    "my_model.fit(x_train, y_train, epochs=30, verbose=2)\n",
    "mse, mae = my_model.evaluate(x_test, y_test)\n",
    "print(f\"{mse = :.3f}\\n{mae = :.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utilize `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "ds_train = ds_train.shuffle(800).batch(32).map(lambda x, y: (x.merge(), y))\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "ds_test = ds_test.batch(32).map(lambda x, y: (x.merge(), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 - 2s - loss: 0.7368 - mae: 0.6331 - 2s/epoch - 69ms/step\n",
      "Epoch 2/30\n",
      "25/25 - 0s - loss: 0.5568 - mae: 0.5576 - 116ms/epoch - 5ms/step\n",
      "Epoch 3/30\n",
      "25/25 - 0s - loss: 0.4925 - mae: 0.5142 - 121ms/epoch - 5ms/step\n",
      "Epoch 4/30\n",
      "25/25 - 0s - loss: 0.4680 - mae: 0.5071 - 117ms/epoch - 5ms/step\n",
      "Epoch 5/30\n",
      "25/25 - 0s - loss: 0.5276 - mae: 0.5262 - 126ms/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "25/25 - 0s - loss: 0.4683 - mae: 0.5101 - 115ms/epoch - 5ms/step\n",
      "Epoch 7/30\n",
      "25/25 - 0s - loss: 0.7421 - mae: 0.6353 - 118ms/epoch - 5ms/step\n",
      "Epoch 8/30\n",
      "25/25 - 0s - loss: 0.5661 - mae: 0.5624 - 119ms/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "25/25 - 0s - loss: 0.6187 - mae: 0.5758 - 115ms/epoch - 5ms/step\n",
      "Epoch 10/30\n",
      "25/25 - 0s - loss: 0.4843 - mae: 0.5187 - 118ms/epoch - 5ms/step\n",
      "Epoch 11/30\n",
      "25/25 - 0s - loss: 0.4198 - mae: 0.4663 - 115ms/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "25/25 - 0s - loss: 0.5075 - mae: 0.5233 - 116ms/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "25/25 - 0s - loss: 0.4685 - mae: 0.5125 - 115ms/epoch - 5ms/step\n",
      "Epoch 14/30\n",
      "25/25 - 0s - loss: 0.4841 - mae: 0.5162 - 116ms/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "25/25 - 0s - loss: 0.4204 - mae: 0.4799 - 116ms/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "25/25 - 0s - loss: 0.4846 - mae: 0.5111 - 115ms/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "25/25 - 0s - loss: 0.5323 - mae: 0.5372 - 115ms/epoch - 5ms/step\n",
      "Epoch 18/30\n",
      "25/25 - 0s - loss: 0.5039 - mae: 0.5320 - 117ms/epoch - 5ms/step\n",
      "Epoch 19/30\n",
      "25/25 - 0s - loss: 0.5189 - mae: 0.5375 - 117ms/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "25/25 - 0s - loss: 0.4009 - mae: 0.4698 - 116ms/epoch - 5ms/step\n",
      "Epoch 21/30\n",
      "25/25 - 0s - loss: 0.4150 - mae: 0.4782 - 113ms/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "25/25 - 0s - loss: 0.3693 - mae: 0.4576 - 116ms/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "25/25 - 0s - loss: 0.4283 - mae: 0.4997 - 113ms/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "25/25 - 0s - loss: 0.4129 - mae: 0.4686 - 119ms/epoch - 5ms/step\n",
      "Epoch 25/30\n",
      "25/25 - 0s - loss: 0.4904 - mae: 0.5291 - 115ms/epoch - 5ms/step\n",
      "Epoch 26/30\n",
      "25/25 - 0s - loss: 0.5079 - mae: 0.5207 - 117ms/epoch - 5ms/step\n",
      "Epoch 27/30\n",
      "25/25 - 0s - loss: 0.4435 - mae: 0.5050 - 116ms/epoch - 5ms/step\n",
      "Epoch 28/30\n",
      "25/25 - 0s - loss: 0.4175 - mae: 0.4775 - 115ms/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "25/25 - 0s - loss: 0.3828 - mae: 0.4605 - 115ms/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "25/25 - 0s - loss: 0.3333 - mae: 0.4177 - 118ms/epoch - 5ms/step\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.3394 - mae: 0.8599\n",
      "mse = 1.339\n",
      "mae = 0.860\n"
     ]
    }
   ],
   "source": [
    "sequential_model.compile('adam', 'mse', ['mae'])\n",
    "sequential_model.fit(ds_train, epochs=30, verbose=2)\n",
    "mse, mae = sequential_model.evaluate(x_test, y_test)\n",
    "print(f\"{mse = :.3f}\\n{mae = :.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load model with `tf.saved_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_9 in the SavedModel.\n",
      "Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpv6iggcj5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type molgraph.tensors.graph_tensor.GraphTensorSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "Assets written to: /tmp/tmpv6iggcj5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1)\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "file = tempfile.NamedTemporaryFile()\n",
    "filename = file.name\n",
    "file.close()\n",
    "\n",
    "tf.saved_model.save(sequential_model, filename)\n",
    "loaded_model = tf.saved_model.load(filename)\n",
    "\n",
    "print(loaded_model(x_train).shape)\n",
    "\n",
    "shutil.rmtree(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_9 in the SavedModel.\n",
      "Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprs6l5asq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type molgraph.tensors.graph_tensor.GraphTensorSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "Assets written to: /tmp/tmprs6l5asq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 5ms/step - loss: 0.6140 - mae: 0.5990\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "file = tempfile.NamedTemporaryFile()\n",
    "filename = file.name\n",
    "file.close()\n",
    "\n",
    "sequential_model.save(filename)\n",
    "loaded_model = tf.keras.models.load_model(filename)\n",
    "\n",
    "loaded_model.fit(ds_train, epochs=1)\n",
    "\n",
    "shutil.rmtree(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
