{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf6ab61a",
   "metadata": {},
   "source": [
    "# Benchmarking MolGraph\n",
    "\n",
    "### Paper\n",
    "\n",
    "The benchmarking in this notebook aims to reproduce, with an up-to-date version of MolGraph, the benchmarking results of the published paper [MolGraph: a Python package for the implementation of molecular graphs and graph neural networks with TensorFlow and Keras](https://doi.org/10.48550/arXiv.2208.09944). The paper is also an introduction to MolGraph.\n",
    "\n",
    "### Dataset\n",
    "The datasets used for benchmarking are mostly datasets from [MoleculeNet](https://moleculenet.org/datasets-1).\n",
    "\n",
    "### Requirements\n",
    "The latest benchmarking was performed with:\n",
    "\n",
    "- Ubuntu 22.04\n",
    "    - Python 3.10 \n",
    "        - Keras 2.15\n",
    "        - TensorFlow 2.15\n",
    "        - MolGraph 0.7.8\n",
    "\n",
    "(Python 3.10 and TensorFlow/Keras 2.15 are currently required.)\n",
    "\n",
    "### Installation\n",
    "\n",
    "For CPU users, install MolGraph as follows:\n",
    "\n",
    "```\n",
    "pip install molgraph\n",
    "```\n",
    "For GPU support:\n",
    "```\n",
    "pip install molgraph[gpu]\n",
    "```\n",
    "\n",
    "(TensorFlow, Keras, and Pandas are installed automatically.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e21ee4c",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1308410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from molgraph import layers\n",
    "from molgraph import chemistry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc42be0b",
   "metadata": {},
   "source": [
    "## Select GNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8016c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNNConv = layers.GATConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc731e7",
   "metadata": {},
   "source": [
    "## Select dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'lipophilicity'\n",
    "dataset_config = getattr(chemistry.benchmark.configs, dataset_name)\n",
    "dataset = chemistry.datasets.get(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf0fad7",
   "metadata": {},
   "source": [
    "## Specify hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06c0827",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('./')\n",
    "\n",
    "NUM_EPOCHS = 300\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "LR_INITIAL = 1e-4\n",
    "LR_END = 1e-6\n",
    "LR_PATIENCE = 10\n",
    "LR_DECAY = 0.1\n",
    "\n",
    "GNN_KWARGS = {\n",
    "    'units': 128,\n",
    "    'normalization': 'batch_norm', \n",
    "    # 'kernel_initializer': keras.initializers.TruncatedNormal(stddev=0.005),\n",
    "}\n",
    "\n",
    "DNN_KWARGS = {\n",
    "    'units': 1024,\n",
    "    'activation': 'relu'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd99b7",
   "metadata": {},
   "source": [
    "## Specify molecular graph encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c80a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = chemistry.MolecularGraphEncoder(\n",
    "    atom_encoder=chemistry.Featurizer([\n",
    "        chemistry.features.Symbol(),\n",
    "        chemistry.features.Hybridization(),\n",
    "        chemistry.features.FormalCharge(),\n",
    "        chemistry.features.TotalNumHs(),\n",
    "        chemistry.features.TotalValence(),\n",
    "        chemistry.features.NumRadicalElectrons(),\n",
    "        chemistry.features.Degree(),\n",
    "        chemistry.features.ChiralCenter(),\n",
    "        chemistry.features.Aromatic(),\n",
    "        chemistry.features.Ring(),\n",
    "        chemistry.features.Hetero(),\n",
    "        chemistry.features.HydrogenDonor(),\n",
    "        chemistry.features.HydrogenAcceptor(),\n",
    "        chemistry.features.CIPCode(),\n",
    "        chemistry.features.ChiralCenter(),\n",
    "        chemistry.features.RingSize(),\n",
    "        chemistry.features.Ring(),\n",
    "        chemistry.features.CrippenLogPContribution(),\n",
    "        chemistry.features.CrippenMolarRefractivityContribution(),\n",
    "        chemistry.features.TPSAContribution(),\n",
    "        chemistry.features.LabuteASAContribution(),\n",
    "        chemistry.features.GasteigerCharge(),\n",
    "    ]),\n",
    "    bond_encoder=chemistry.Featurizer([\n",
    "        chemistry.features.BondType(),\n",
    "        chemistry.features.Conjugated(),\n",
    "        chemistry.features.Rotatable(),\n",
    "        chemistry.features.Ring(),\n",
    "        chemistry.features.Stereo(),\n",
    "    ]),\n",
    "    positional_encoding_dim=16,\n",
    "    self_loops=False\n",
    ")\n",
    "\n",
    "record_writer = chemistry.tf_records.writer \n",
    "record_loader = chemistry.tf_records.load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975bdb8f",
   "metadata": {},
   "source": [
    "## Benchmark models on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be222c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and load tf records:\n",
    "data = {}\n",
    "for subset_name, subset in dataset.items():\n",
    "    path = PATH / f'cache/tf_records/{dataset_name}/{subset_name}/'\n",
    "    with record_writer(path) as writer:\n",
    "        writer.write(subset, encoder)\n",
    "\n",
    "    keys = list(subset.keys())\n",
    "    keys.remove('index')\n",
    "\n",
    "    data[subset_name] = record_loader(\n",
    "        path=path, \n",
    "        extract_tuple=keys, \n",
    "        shuffle_tf_records=True if subset_name == 'train' else False)\n",
    "\n",
    "    if subset_name == 'train':\n",
    "        data[subset_name] = data[subset_name].shuffle(4096)\n",
    "\n",
    "    data[subset_name] = data[subset_name].batch(BATCH_SIZE).prefetch(-1)\n",
    "\n",
    "# Build model:\n",
    "node_preprocessing = layers.NodeMinMaxScaling(\n",
    "    feature_range=(0, 1), threshold=True)\n",
    "edge_preprocessing = layers.EdgeMinMaxScaling(\n",
    "    feature_range=(0, 1), threshold=True)\n",
    "node_preprocessing.adapt(data['train'].map(lambda x, *args: x))\n",
    "edge_preprocessing.adapt(data['train'].map(lambda x, *args: x))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.GNNInput(type_spec=data['train'].element_spec[0]),\n",
    "    node_preprocessing,\n",
    "    edge_preprocessing,\n",
    "    layers.LaplacianPositionalEncoding(),\n",
    "    GNNConv(**GNN_KWARGS),\n",
    "    GNNConv(**GNN_KWARGS),\n",
    "    GNNConv(**GNN_KWARGS),\n",
    "    layers.Readout(),\n",
    "    keras.layers.Dense(**DNN_KWARGS),\n",
    "    keras.layers.Dense(**DNN_KWARGS),\n",
    "    keras.layers.Dense(\n",
    "        units=dataset_config['num_tasks'],\n",
    "        activation='sigmoid' if dataset_config['task_type'] == 'classification' else 'linear'\n",
    "    )\n",
    "])\n",
    "\n",
    "# Train and evaluate model:\n",
    "optimizer = keras.optimizers.Adam(LR_INITIAL)\n",
    "loss = keras.losses.deserialize(dataset_config['loss'])\n",
    "metrics = [keras.metrics.deserialize(dataset_config['metric'])]\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_' + metrics[0].name,\n",
    "        factor=LR_DECAY,\n",
    "        patience=LR_PATIENCE,\n",
    "        min_lr=LR_END,\n",
    "        mode='min' if not metrics[0].name.endswith('auc') else 'max',\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_' + metrics[0].name,\n",
    "        patience=LR_PATIENCE * 2,\n",
    "        mode='min' if not metrics[0].name.endswith('auc') else 'max',\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "model.compile(optimizer, loss, metrics)\n",
    "\n",
    "history = model.fit(\n",
    "    data['train'], \n",
    "    validation_data=data['validation'], \n",
    "    epochs=NUM_EPOCHS, \n",
    "    callbacks=callbacks_list,\n",
    "    verbose=2)\n",
    "\n",
    "result = model.evaluate(data['test'], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83048d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4a4d0bd",
   "metadata": {},
   "source": [
    "## Run cell below to remove cache (tf records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f16710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "cache_path = PATH / 'cache'\n",
    "\n",
    "if cache_path.exists() and cache_path.is_dir():\n",
    "    shutil.rmtree(cache_path)\n",
    "    print(f\"The folder '{cache_path}' and its subfolders have been removed.\")\n",
    "else:\n",
    "    print(f\"The folder '{cache_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae6534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
